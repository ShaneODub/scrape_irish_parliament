View(extractedData)
# Order the levels by number of jobs
extractedData %>%
group_by(recruiter) %>%
count()
# Order the levels by number of jobs
extractedData %>%
group_by(recruiter) %>%
count() %>%
order(decreasing = TRUE)
extractedData %>%
group_by(recruiter) %>%
count()
# Order the levels by number of jobs
recruiter_count <-
extractedData %>%
group_by(recruiter) %>%
count()
recruiter_count
View(recruiter_count)
# Order the levels by number of jobs
recruiter_count <-
extractedData %>%
group_by(recruiter) %>%
count() %>%
order(n)
recruiter_count[order(recruiter_count$n),]
recruiter_count[order(recruiter_count$n, decreasing = TRUE),]
extractedData %>%
group_by(recruiter) %>%
count() %>%
arrange(n)
# Order the levels by number of jobs
recruiter_count <-
extractedData %>%
group_by(recruiter) %>%
count() %>%
arrange(desc(n))
View(recruiter_count)
install.packages("forcats")
install.packages("forcats")
library(forcats)
str(extractedData)
ggplot(data = extractedData,
mapping = aes(x = recruiter) +
ggplot(data = extractedData,
mapping = aes(x = recruiter)) +
geom_bar() +
coord_flip()
library(ggplot2)
ggplot(data = extractedData,
mapping = aes(x = recruiter)) +
geom_bar() +
coord_flip()
extractedData$recruiter <-
fct_infreq(extractedData$recruiter)
str(extractedData)
ggplot(data = extractedData,
mapping = aes(x = recruiter)) +
geom_bar() +
coord_flip()
extractedData$recruiter <-
fct_infreq(-extractedData$recruiter)
ggplot(data = extractedData,
mapping = aes(x = recruiter)) +
geom_bar()
ggplot(data = extractedData,
mapping = aes(x = recruiter)) +
geom_bar() +
coord_flip()
extractedData$recruiter <-
fct_infreq(extractedData$recruiter) %>%
factor(levels = -levels)
extractedData$job_title <-
fct_infreq(extractedData$job_title))
extractedData$job_title <-
fct_infreq(extractedData$job_title)
ggplot(data = extractedData,
mapping = aes(x = job_title)) +
geom_bar() +
coord_flip()
# First, wiple the slate clean
rm(list = ls())
# Pacman will help to load and install any required packages
install.packages("pacman")
pacman::p_load(rvest, dplyr)
install.packages("pacman")
# Members of current and previous parliaments are listed on this URL:
url <-
"https://www.oireachtas.ie/en/members/tds/?term=%2Fie%2Foireachtas%2Fhouse%2Fdail%2F"
# We'll store the pages after scraping
list_of_pages <- vector("list", 72)
for (page in 1:9){
list_of_pages[[page + 9 * (term - 26)]] <-
paste0(url, term, '&tab=constituency&page=', page) %>%
read_html()
Sys.sleep(3)
print(page + 9 * (term - 26))
}
pacman::p_load(rvest, dplyr)
for (term in 26:33) {
for (page in 1:9){
list_of_pages[[page + 9 * (term - 26)]] <-
paste0(url, term, '&tab=constituency&page=', page) %>%
read_html()
Sys.sleep(3)
print(page + 9 * (term - 26))
}
}
View(list_of_pages)
getwd()
setwd("C://Users//Shane//onedrive//projects//taking_the_mick")
getwd()
saveRDS(list_of_pages, file = "")
saveRDS(list_of_pages, file = "//data//list_of_pages.rds")
saveRDS(list_of_pages, file = "data//list_of_pages.rds")
extracted_data <- tibble(term = integer(1500),
member = character(1500),
constituency = character(1500),
party = character(1500))
for (term in 26:26) {
for (page in 1:1){
for (td in 1:20) {
extracted_data$term[[20 * (page - 1) + 9 * (term - 26) + td]] <- term
extracted_data$member[[20 * (page - 1) + 9 * (term - 26) + td]] <-
html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
}
for (page in 1:2){
for (td in 1:20) {
extracted_data$term[[20 * (page - 1) + 9 * (term - 26) + td]] <- term
extracted_data$member[[20 * (page - 1) + 9 * (term - 26) + td]] <-
html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
extracted_data <- tibble(term = integer(1500),
member = character(1500),
constituency = character(1500),
party = character(1500),
profile_url = character(1500))
# Scrape the data and store it in a tibble  ------------------------------
# Members of current and previous parliaments are listed on this URL:
url <-
"https://www.oireachtas.ie/en/members/tds/?term=%2Fie%2Foireachtas%2Fhouse%2Fdail%2F"
# We'll start with the 33rd parliament, on page 1 of the list of members.
# # term <- 26
# current_term <- 33
# page <- 1
# last_page <- 9
# We'll store the pages after scraping
list_of_pages <- vector("list", 72)
# Now loop through the 26th to 33rd Dail, grabbing and storing 9 pages from each.
for (term in 26:33) {
for (page in 1:9){
list_of_pages[[page + 9 * (term - 26)]] <-
paste0(url, term, '&tab=constituency&page=', page) %>%
read_html()
Sys.sleep(3)
print(page + 9 * (term - 26))
}
}
# Output the list so I won't have to scrape again
saveRDS(list_of_pages, file = "data//list_of_pages.rds")
extracted_data <- tibble(term = integer(1500),
member = character(1500),
constituency = character(1500),
party = character(1500),
profile_url = character(1500))
for (term in 26:33) {
for (page in 1:9){
for (td in 1:20) {
extracted_data$term[[20 * (page - 1) + 9 * (term - 26) + td]] <- term
# extracted_data$member[[20 * (page - 1) + 9 * (term - 26) + td]] <-
#   html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
#                        css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
}
# need something much simpler
list_of_pages <- readRDS("data//list_of_pages.rds")
extracted_data <- tibble(term = integer(1500),
member = character(1500),
constituency = character(1500),
party = character(1500),
profile_url = character(1500))
for (term in 26:33) {
for (page in 1:9){
for (td in 1:20) {
extracted_data$term[[20 * (page - 1) + 9 * (term - 26) + td]] <- term
# extracted_data$member[[20 * (page - 1) + 9 * (term - 26) + td]] <-
#   html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
#                        css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
}
for (term in 26:26) {
for (page in 1:9){
for (td in 1:20) {
extracted_data$term[[20 * (page - 1) + 9 * (term - 26) + td]] <- term
# extracted_data$member[[20 * (page - 1) + 9 * (term - 26) + td]] <-
#   html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
#                        css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
}
extracted_data$term <- NA
View(extracted_data)
for (term in 26:26) {
for (page in 1:9){
for (td in 1:20) {
extracted_data$term[[20 * (page - 1) + 9 * (term - 26) + td]] <- term
# extracted_data$member[[20 * (page - 1) + 9 * (term - 26) + td]] <-
#   html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
#                        css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
}
for (term in 26:27) {
for (page in 1:9){
for (td in 1:20) {
extracted_data$term[[20 * (page - 1) + 9 * (term - 26) + td]] <- term
# extracted_data$member[[20 * (page - 1) + 9 * (term - 26) + td]] <-
#   html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
#                        css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
}
for (term in 26:27) {
for (page in 1:9) {
for (td in 1:20) {
extracted_data$term[[(180 * (term - 26)) + (20 * (page - 1)) + td]] <- term
# extracted_data$member[[20 * (page - 1) + 9 * (term - 26) + td]] <-
#   html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
#                        css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
}
for (term in 26:33) {
for (page in 1:9) {
for (td in 1:20) {
extracted_data$term[[(180 * (term - 26)) + (20 * (page - 1)) + td]] <- term
extracted_data$member[[(180 * (term - 26)) + (20 * (page - 1)) + td]] <-
html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
}
html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
css = "#constituency .c-member-list-item__name-content"))[[td]]
html_text(html_nodes(list_of_pages[[1 + 9 * (26 - 26)]],
css = "#constituency .c-member-list-item__name-content"))[[1]]
html_text(html_nodes(list_of_pages[[1 + 9 * (26 - 26)]],
css = "#constituency .c-member-list-item__name-content"))
View(list_of_pages)
for (term in 26:33) {
for (page in 1:9){
list_of_pages[[page + 9 * (term - 26)]] <-
paste0(url, term, '&tab=constituency&page=', page) %>%
read_html()
Sys.sleep(3)
print(page + 9 * (term - 26))
}
}
View(list_of_pages)
# Output the list so I won't have to scrape again
saveRDS(list_of_pages, file = "data//list_of_pages.rds")
extracted_data <- tibble(term = integer(1440),
member = character(1440),
constituency = character(1440),
party = character(1440),
profile_url = character(1440))
length(list_of_pages)
length(list_of_pages[[1]])
html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],css = "#constituency .c-member-list-item__name-content"))[[td]]
td
page + 9 * (term - 26)
# Make a 1500-length tibble because 8 terms X 9 pages X 20 TDs = 1440
extracted_data <- tibble(term = integer(1440),
member = character(1440),
constituency = character(1440),
party = character(1440),
profile_url = character(1440))
for (term in 26:33) {
for (page in 1:9) {
for (td in 1:20) {
extracted_data$term[[(180 * (term - 26)) + (20 * (page - 1)) + td]] <- term
extracted_data$member[[(180 * (term - 26)) + (20 * (page - 1)) + td]] <-
html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
}
# Make a 1500-length tibble because 8 terms X 9 pages X 20 TDs = 1440
extracted_data <- tibble(term = integer(1440),
member = character(1440),
constituency = character(1440),
party = character(1440),
profile_url = character(1440))
for (term in 26:33) {
for (page in 1:8) {
for (td in 1:20) {
extracted_data$term[[(180 * (term - 26)) + (20 * (page - 1)) + td]] <- term
extracted_data$member[[(180 * (term - 26)) + (20 * (page - 1)) + td]] <-
html_text(html_nodes(list_of_pages[[page + 9 * (term - 26)]],
css = "#constituency .c-member-list-item__name-content"))[[td]]
}
}
}
html_text(html_nodes(list_of_pages[[1]]))
html_text(html_nodes(list_of_pages[[1]], css = #term))
)
)
html_text(html_nodes(list_of_pages[[1]], css = "#term"))
html_text(html_nodes(list_of_pages[[1]], css = ".text-results span"))
html_text(html_nodes(list_of_pages[[10]], css = ".text-results span"))
html_text(html_nodes(list_of_pages[[19]], css = ".text-results span"))
# Make a 1500-length tibble because 8 terms X 9 pages X 20 TDs = 1440
extracted_data <- tibble(term = integer(1440),
period = character(1440),
number_of_seats = integer(1440),
member = character(1440),
constituency = character(1440),
party = character(1440),
profile_url = character(1440))
list_of_pages[[19]] %>% html_text()
list_of_pages[[19]] %>% html_text() %>% html_node(css = ".text-results span")
html_text(html_nodes(list_of_pages[[19]], css = ".text-results span"))
list_of_pages[[19]] %>% html_nodes() %>% html_text(css = ".text-results span")
list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text()
list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text()[[6]]
list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text()
list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text()[[6,]]
str(list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text())
list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text()
list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text() %>% pull(6)
list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text() %>% nth(6)
str(list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text() %>% nth(6))
list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text() %>% nth(6) %>% as.numeric()
list_of_pages[[19]] %>% html_nodes(css = ".text-results span") %>% html_text() %>% nth(2)
list_of_pages[[19]] %>% html_nodes(css = #constituency .c-member-list-item__name-content") %>% html_text()
)
list_of_pages[[19]] %>% html_nodes(css = "#constituency .c-member-list-item__name-content") %>% html_text()
list_of_pages[[19]] %>% html_nodes(css = "#constituency .c-member-list-item__name-content") %>% html_text() %>% nth(7)
number_of_seats <-
html_nodes(css = ".text-results span") %>%
html_text() %>%
nth(6) %>%
as.numeric()
number_of_seats <-
page %>%
html_nodes(css = ".text-results span") %>%
html_text() %>%
nth(6) %>%
as.numeric()
number_of_seats <-
page %>%
html_nodes(css = ".text-results span") %>%
html_text() %>%
nth(6)
number_of_seats <-
page %>%
html_nodes(css = ".text-results span") %>%
html_text()
number_of_seats <-
page %>%
html_nodes(css = ".text-results span")
number_of_pages
number_of_seats
for (page in list_of_pages) {print page}
for (page in list_of_pages) {print (page)}
for (page in list_of_pages) {print (page)}[[1]]
print(list_of_pages[[1]])
print(list_of_pages[[72]])
print(list_of_pages[[73]])
list_of_pages[[1]] %>% html_nodes(css = ".text-results span") %>% html_text()
number_of_seats <- list_of_pages[[1]] %>% html_nodes(css = ".text-results span") %>% html_text()
number_of_seats
rm(number_of_seats)
myfunc <- function (x) {x %>% html_nodes(css = ".text-results span") %>% html_text()}
myfunc(list_of_pages[[1]])
myfunc(list_of_pages)
lapply(list_of_pages, myfunc)
for (page in list_of_pages){
print(page)
}
for (page in list_of_pages){
print(str(page))
}
str(list_of_pages[[1]][[1]])
str(list_of_pages[[1]][[2]])
str(list_of_pages[[1]][[3]])
list_of_pages[[11]] %>% html_nodes(css = ".text-results span") %>%
html_text() %>%
nth(2)
list_of_pages[[11]] %>% html_nodes(css = "#constituency .c-member-list-item__name-content") %>% html_text()
cbind(list_of_pages[[11]] %>% html_nodes(css = "#constituency .c-member-list-item__name-content") %>% html_text(),list_of_pages[[11]] %>% html_nodes(css = "#constituency .c-member-list-item__party-content") %>% html_text())
list_of_pages[[1]] %>% html_nodes(css = "#constituency .u-btn-secondary") %>%
html_text()
list_of_pages[[1]] %>% html_nodes(css = "#constituency .u-btn-secondary") %>%
html_attr()
list_of_pages[[1]] %>% html_nodes(css = "#constituency .u-btn-secondary") %>%
html_attr(href)
list_of_pages[[1]] %>% html_nodes(css = "#constituency .u-btn-secondary") %>%
html_attr(a)
list_of_pages[[1]] %>% html_nodes(css = "#constituency .u-btn-secondary") %>%
html_attr("href")
rep(a,5)
rep('a',5)
rep(("a","b"),3)
rep(c("a","b"),3)
tibble(list_of_pages[[11]] %>% html_nodes(css = "#constituency .c-member-list-item__name-content") %>% html_text(),list_of_pages[[11]] %>% html_nodes(css = "#constituency .c-member-list-item__party-content") %>% html_text())
# Unnamed arguments are named with their expression:
a <- 1:5
tibble(a, a * 2)
# Scalars (vectors of length one) are recycled:
tibble(a, b = a * 2, c = 1)
tibble(a,b,c)
tibble_list = vector("list", 72)
i <- 1
for (page in list_of_pages){
tibble_list[[i]] <-
tibble(
full_name = page %>%
html_nodes(css = "#constituency .c-member-list-item__name-content") %>%
html_text(),
constituency = page %>%
html_nodes(css = "#constituency .c-member-list-item__constituency-content") %>%
html_text(),
party = page %>%
html_nodes(css = "#constituency .c-member-list-item__party-content") %>%
html_text(),
profile_url = page %>%
html_nodes(css = "#constituency .u-btn-secondary") %>%
html_attr("href"),
dail_term = page  %>%
html_nodes(css = ".text-results span") %>%
html_text() %>%
nth(2),
dail_period = page  %>%
html_nodes(css = ".text-results span") %>%
html_text() %>%
nth(4)
)
}
View(tibble_list)
tibble_list[[1]]
page <- list_of_pages[[1]]
i <- 1
tibble_list[[i]] <-
tibble(
full_name = page %>%
html_nodes(css = "#constituency .c-member-list-item__name-content") %>%
html_text(),
constituency = page %>%
html_nodes(css = "#constituency .c-member-list-item__constituency-content") %>%
html_text(),
party = page %>%
html_nodes(css = "#constituency .c-member-list-item__party-content") %>%
html_text(),
profile_url = page %>%
html_nodes(css = "#constituency .u-btn-secondary") %>%
html_attr("href"),
dail_term = page  %>%
html_nodes(css = ".text-results span") %>%
html_text() %>%
nth(2),
dail_period = page  %>%
html_nodes(css = ".text-results span") %>%
html_text() %>%
nth(4)
)
View(tibble_list)
length(list_of_pages)
for (page in list_of_pages){if(page == list_of_pages[[72]]){print 't'}}
for (page in list_of_pages){if(page == list_of_pages[[72]]){print ('t')}}
tibble_list = vector("list", 72)
for (i in 1:72){
tibble_list[[i]] <-
tibble(
full_name = list_of_pages[[i]] %>%
html_nodes(css = "#constituency .c-member-list-item__name-content") %>%
html_text(),
constituency = list_of_pages[[i]] %>%
html_nodes(css = "#constituency .c-member-list-item__constituency-content") %>%
html_text(),
party = list_of_pages[[i]] %>%
html_nodes(css = "#constituency .c-member-list-item__party-content") %>%
html_text(),
profile_url = list_of_pages[[i]] %>%
html_nodes(css = "#constituency .u-btn-secondary") %>%
html_attr("href"),
dail_term = list_of_pages[[i]]  %>%
html_nodes(css = ".text-results span") %>%
html_text() %>%
nth(2),
dail_period = list_of_pages[[i]]  %>%
html_nodes(css = ".text-results span") %>%
html_text() %>%
nth(4)
)
}
View(tibble_list)
bind_rows(tibble_list) %>% View()
rm(extracted_data)
View(list_of_pages)
# Output the list so I won't have to scrape again
saveRDS(list_of_pages, file = "output//list_of_pages.rds")
eight_dail_terms <- bind_rows(tibble_list)
View(eight_dail_terms)
